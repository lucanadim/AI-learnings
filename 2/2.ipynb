{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: 'data\\\\Arbeit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m\n\u001b[0;32m     25\u001b[0m                     data\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     26\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBetreff\u001b[39m\u001b[38;5;124m\"\u001b[39m: row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBetreff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     27\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInhalt\u001b[39m\u001b[38;5;124m\"\u001b[39m: row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInhalt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     28\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: folder  \u001b[38;5;66;03m# Ordnername als Label\u001b[39;00m\n\u001b[0;32m     29\u001b[0m                     })\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m---> 32\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_from_folders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# === 3. Datenaufteilung in Training und Test ===\u001b[39;00m\n\u001b[0;32m     35\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m train_test_split(data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m, in \u001b[0;36mload_data_from_folders\u001b[1;34m(base_path, folders)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m folders:\n\u001b[0;32m     18\u001b[0m     folder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, folder)\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     21\u001b[0m             file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: 'data\\\\Arbeit'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# === 1. Ordnernamen anpassen ===\n",
    "folders = [\"Arbeit\", \"Finanzen\", \"Werbung\"]  # Hier einfach deine Ordnernamen eintragen\n",
    "base_path = \"data\"  # Der Pfad zu deinem Hauptverzeichnis mit den Ordnern\n",
    "\n",
    "# === 2. Datenimport: CSV-Dateien laden ===\n",
    "def load_data_from_folders(base_path, folders):\n",
    "    data = []\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                # CSV-Datei lesen\n",
    "                csv_data = pd.read_csv(file_path)\n",
    "                for _, row in csv_data.iterrows():\n",
    "                    data.append({\n",
    "                        \"Betreff\": row.get(\"Betreff\", \"\"),\n",
    "                        \"Inhalt\": row.get(\"Inhalt\", \"\"),\n",
    "                        \"Label\": folder  # Ordnername als Label\n",
    "                    })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "data = load_data_from_folders(base_path, folders)\n",
    "\n",
    "# === 3. Datenaufteilung in Training und Test ===\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 4. Textdaten vorbereiten: Tokenisierung ===\n",
    "# Tokenizer erstellen und auf Trainingsdaten anpassen\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(train_data[\"Inhalt\"])\n",
    "\n",
    "# Textdaten in Sequenzen umwandeln\n",
    "x_train = tokenizer.texts_to_matrix(train_data[\"Inhalt\"], mode=\"tfidf\")\n",
    "x_test = tokenizer.texts_to_matrix(test_data[\"Inhalt\"], mode=\"tfidf\")\n",
    "\n",
    "# Labels in numerische Werte umwandeln\n",
    "label_map = {folder: idx for idx, folder in enumerate(folders)}  # Ordner zu Index\n",
    "y_train = to_categorical(train_data[\"Label\"].map(label_map), num_classes=len(folders))\n",
    "y_test = to_categorical(test_data[\"Label\"].map(label_map), num_classes=len(folders))\n",
    "\n",
    "# === 5. Modell erstellen ===\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(folders), activation='softmax')  # Ausgabe hat so viele Klassen wie Ordner\n",
    "])\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# === 6. Modell trainieren ===\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=16, validation_data=(x_test, y_test))\n",
    "\n",
    "# === 7. Belohnungssystem simulieren ===\n",
    "def reward_system(predicted_folder, true_folder):\n",
    "    if predicted_folder == true_folder:\n",
    "        return 1  # Richtige Zuordnung\n",
    "    else:\n",
    "        return -1  # Falsche Zuordnung\n",
    "\n",
    "# === 8. Aufgaben: Vorhersagen und Belohnung auswerten ===\n",
    "def evaluate_model(data, tokenizer, model, label_map, folders):\n",
    "    score = 0\n",
    "    for _, row in data.iterrows():\n",
    "        # Text in Matrix umwandeln\n",
    "        x = tokenizer.texts_to_matrix([row[\"Inhalt\"]], mode=\"tfidf\")\n",
    "        # Vorhersage durchführen\n",
    "        predictions = model.predict(x)\n",
    "        predicted_label = folders[np.argmax(predictions)]  # Index zurück in Ordnername\n",
    "        true_label = row[\"Label\"]\n",
    "\n",
    "        # Belohnung berechnen\n",
    "        reward = reward_system(predicted_label, true_label)\n",
    "        score += reward\n",
    "\n",
    "        print(f\"Betreff: {row['Betreff']}, Vorhergesagt: {predicted_label}, Korrekt: {true_label}, Belohnung: {reward}\")\n",
    "    return score\n",
    "\n",
    "# Modell bewerten\n",
    "final_score = evaluate_model(test_data, tokenizer, model, label_map, folders)\n",
    "print(f\"Gesamte Belohnung: {final_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
